{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with LatentProbe Advanced\n",
    "\n",
    "This notebook provides a quick start guide to using LatentProbe Advanced for AI red teaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Configuration\n",
    "\n",
    "Create a `.env` file with your model configurations. Copy `example_config.env` to `.env` and update with your credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy example config to .env\n",
    "import shutil\n",
    "shutil.copy('example_config.env', '.env')\n",
    "print(\"Created .env file. Please update it with your credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Start Example\n",
    "\n",
    "Here's a simple example of how to use LatentProbe Advanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Example configuration (update these with your actual models)\n",
    "target_model_config = {\n",
    "    \"provider\": \"lmstudio\",  # or \"openai\", \"ollama\"\n",
    "    \"api_key\": os.getenv(\"LM_STUDIO_API_KEY\", \"not-needed\"),\n",
    "    \"base_url\": os.getenv(\"LM_STUDIO_BASE_URL\", \"http://localhost:1234/v1\"),\n",
    "    \"model\": \"your-local-model-name\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "\n",
    "judge_model_config = {\n",
    "    \"provider\": \"lmstudio\",\n",
    "    \"api_key\": os.getenv(\"LM_STUDIO_API_KEY\", \"not-needed\"),\n",
    "    \"base_url\": os.getenv(\"LM_STUDIO_BASE_URL\", \"http://localhost:1234/v1\"),\n",
    "    \"model\": \"your-judge-model-name\",\n",
    "    \"temperature\": 0.3,\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate and Test a Prompt\n",
    "\n",
    "Open the main notebook `AdversarialPromptGenerator_with_modules.ipynb` to:\n",
    "1. Generate adversarial prompts\n",
    "2. Test them against target models\n",
    "3. Evaluate responses\n",
    "4. Export results\n",
    "\n",
    "Refer to `User_Guide.md` for detailed instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "1. Review the `User_Guide.md` for comprehensive instructions\n",
    "2. Explore the main notebook `AdversarialPromptGenerator_with_modules.ipynb`\n",
    "3. Run sample experiments with your models\n",
    "4. Customize attack scenarios for your specific use cases\n",
    "\n",
    "For any questions or issues, refer to the documentation or open an issue on the repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}