# Example Environment Configuration for LatentProbe Advanced

# LM Studio Configuration (for local models)
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_API_KEY=not-needed

# OpenAI Configuration (for API-based models)
# OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1

# Ollama Configuration (for local Ollama models)
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_API_KEY=ollama

# Target Model Selection
# Uncomment the configuration you want to use as your target model

# For LM Studio as target:
# TARGET_PROVIDER=lmstudio
# TARGET_MODEL=your-local-model-name
# TARGET_BASE_URL=http://localhost:1234/v1
# TARGET_API_KEY=not-needed

# For OpenAI as target:
TARGET_PROVIDER=openai
TARGET_MODEL=openai/gpt-oss-20b:free
TARGET_BASE_URL=https://api.openai.com/v1
TARGET_API_KEY=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

# For Ollama as target:
# TARGET_PROVIDER=ollama
# TARGET_MODEL=llama2
# TARGET_BASE_URL=http://localhost:11434/v1
# TARGET_API_KEY=ollama