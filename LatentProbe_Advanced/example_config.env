# Example Environment Configuration for LatentProbe Advanced

# LM Studio Configuration (for local models)
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_API_KEY=not-needed

# OpenAI Configuration (for API-based models)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# Ollama Configuration (for local Ollama models)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama

# Target Model Selection
# Uncomment the configuration you want to use as your target model

# For LM Studio as target:
# TARGET_PROVIDER=lmstudio
# TARGET_MODEL=your-local-model-name
# TARGET_BASE_URL=http://localhost:1234/v1
# TARGET_API_KEY=not-needed

# For OpenAI as target:
TARGET_PROVIDER=openai
TARGET_MODEL=openai/gpt-oss-20b:free
TARGET_BASE_URL=https://api.openai.com/v1
TARGET_API_KEY=

# For Ollama as target:
# TARGET_PROVIDER=ollama
# TARGET_MODEL=llama2
# TARGET_BASE_URL=http://localhost:11434/v1
# TARGET_API_KEY=ollama